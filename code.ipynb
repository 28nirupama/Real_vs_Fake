{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eb74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1Ô∏è‚É£ Import required libraries\n",
    "# ================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6aa44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 2Ô∏è‚É£ Extra Features Class\n",
    "# ================================\n",
    "# This is same as in your extra_features.py\n",
    "\n",
    "emoji_set = set(\n",
    "    \"üòÄüòÅüòÇü§£üòÉüòÑüòÖüòÜüòâüòäüòãüòéüòçüòòüòóüòôüòöüôÇü§óü§©ü§îü§®üòêüòëüò∂üôÑüòèüò£üò•\"\n",
    "    \"üòÆü§êüòØüò™üò´üò¥üòåü§ìüòõüòúüòùü§§üòíüòìüòîüòïüôÉü§ëüò≤‚òπÔ∏èüôÅüòñüòûüòüüò§üò¢üò≠\"\n",
    "    \"üò¶üòßüò®üò©ü§Øüò¨üò∞üò±üò≥ü§™üòµüò°üò†ü§¨\"\n",
    ")\n",
    "\n",
    "class ExtraFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts):\n",
    "        processed = [t if isinstance(t, str) else \"\" for t in texts]\n",
    "\n",
    "        emoji_count = np.array([sum(1 for ch in t if ch in emoji_set) for t in processed]).reshape(-1, 1)\n",
    "        punctuation_ratio = np.array([sum(1 for c in t if c in string.punctuation) / (len(t) + 1) for t in processed]).reshape(-1, 1)\n",
    "        digit_ratio = np.array([sum(1 for c in t if c.isdigit()) / (len(t) + 1) for t in processed]).reshape(-1, 1)\n",
    "        avg_word_len = np.array([\n",
    "            np.mean([len(w) for w in t.split()]) if len(t.split()) > 0 else 0\n",
    "            for t in processed\n",
    "        ]).reshape(-1, 1)\n",
    "\n",
    "        return np.hstack([emoji_count, punctuation_ratio, digit_ratio, avg_word_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d3dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 632\n",
      "label\n",
      "human    316\n",
      "ai       316\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 3Ô∏è‚É£ Load your CSV data\n",
    "# ================================\n",
    "df = pd.read_csv(\"RF_data.csv\")  # Your CSV with Human_Content & AI_Content columns\n",
    "\n",
    "# Combine into a single dataframe\n",
    "human_df = pd.DataFrame({\"text\": df[\"Human_Content\"], \"label\": \"human\"})\n",
    "ai_df = pd.DataFrame({\"text\": df[\"AI_Content\"], \"label\": \"ai\"})\n",
    "df_final = pd.concat([human_df, ai_df], ignore_index=True)\n",
    "\n",
    "# Clean text\n",
    "df_final['text'] = df_final['text'].fillna(\"\").str.strip()\n",
    "\n",
    "print(\"Total samples:\", df_final.shape[0])\n",
    "print(df_final['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14c7823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced samples: (632, 2)\n",
      "label\n",
      "ai       316\n",
      "human    316\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 4Ô∏è‚É£ Balance the classes (oversampling)\n",
    "# ================================\n",
    "human = df_final[df_final.label == \"human\"]\n",
    "ai = df_final[df_final.label == \"ai\"]\n",
    "\n",
    "if len(human) > len(ai):\n",
    "    ai = resample(ai, replace=True, n_samples=len(human), random_state=42)\n",
    "elif len(ai) > len(human):\n",
    "    human = resample(human, replace=True, n_samples=len(ai), random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([human, ai]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"Balanced samples:\", df_balanced.shape)\n",
    "print(df_balanced['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3d218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d11e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 568\n",
      "Testing samples: 64\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 5Ô∏è‚É£ Train-Test Split\n",
    "# ================================\n",
    "X = df_balanced[\"text\"]\n",
    "y = df_balanced[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Testing samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4bdd3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 6Ô∏è‚É£ Vectorization + Extra Features\n",
    "# ================================\n",
    "# TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=15000, ngram_range=(1,3), sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Extra features\n",
    "extra = ExtraFeatures()\n",
    "X_train_extra = extra.fit_transform(X_train)\n",
    "X_test_extra = extra.transform(X_test)\n",
    "\n",
    "# Combine\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_extra])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_extra])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d479ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================\n",
    "# 7Ô∏è‚É£ Train the Linear SVC Model\n",
    "# ================================\n",
    "model = LinearSVC()\n",
    "model.fit(X_train_combined, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebedfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.31%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ai       0.94      0.97      0.95        32\n",
      "       human       0.97      0.94      0.95        32\n",
      "\n",
      "    accuracy                           0.95        64\n",
      "   macro avg       0.95      0.95      0.95        64\n",
      "weighted avg       0.95      0.95      0.95        64\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31  1]\n",
      " [ 2 30]]\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 8Ô∏è‚É£ Evaluate Model\n",
    "# ================================\n",
    "y_pred = model.predict(X_test_combined)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e201a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I had a great day at the park with friends!... Prediction: ai\n",
      "Text: The probability distribution of X is calculated us... Prediction: ai\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 9Ô∏è‚É£ Test on new sentences\n",
    "# ================================\n",
    "def predict_text(text):\n",
    "    vec = tfidf.transform([text])\n",
    "    extra_feat = extra.transform([text])\n",
    "    combined = hstack([vec, extra_feat])\n",
    "    pred = model.predict(combined)[0]\n",
    "    return pred\n",
    "\n",
    "# Example sentences\n",
    "examples = [\n",
    "    \"I had a great day at the park with friends!\",\n",
    "    \"The probability distribution of X is calculated using the formula...\"\n",
    "]\n",
    "\n",
    "for s in examples:\n",
    "    print(f\"Text: {s[:50]}... Prediction: {predict_text(s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61ad516c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 10Ô∏è‚É£ Save model & vectorizer\n",
    "# ================================\n",
    "joblib.dump(model, \"ai_human_model.pkl\")\n",
    "joblib.dump(tfidf, \"vectorizer.pkl\")\n",
    "print(\"Model and vectorizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49878e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_sentences = [\n",
    "    \"I had a fantastic weekend hiking with my friends!\",\n",
    "    \"Can't believe how much I laughed at that movie last night.\",\n",
    "    \"I baked a chocolate cake yesterday and it turned out amazing!\",\n",
    "    \"I feel so tired today, I think I need a nap.\",\n",
    "    \"Hey there! Just wanted to check in and see how you're doing.\"\n",
    "]\n",
    "ai_sentences = [\n",
    "    \"The probability of X is calculated by applying Bayes theorem and integrating over the sample space.\",\n",
    "    \"Machine learning models require training datasets with labeled examples to optimize the loss function efficiently.\",\n",
    "    \"The algorithm demonstrates a time complexity of O(n log n) under the assumption of a balanced binary search tree.\",\n",
    "    \"Quantum computing utilizes qubits which can exist in superposition states to perform parallel computations.\",\n",
    "    \"The economic growth rate is influenced by multiple macroeconomic indicators including inflation, unemployment, and interest rates.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7260ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Human Sentences ===\n",
      "Text: I had a fantastic weekend hiking with my friends!... Prediction: human\n",
      "Text: Can't believe how much I laughed at that movie las... Prediction: human\n",
      "Text: I baked a chocolate cake yesterday and it turned o... Prediction: human\n",
      "Text: I feel so tired today, I think I need a nap.... Prediction: human\n",
      "Text: Hey there! Just wanted to check in and see how you... Prediction: human\n",
      "\n",
      "=== AI Sentences ===\n",
      "Text: The probability of X is calculated by applying Bay... Prediction: ai\n",
      "Text: Machine learning models require training datasets ... Prediction: ai\n",
      "Text: The algorithm demonstrates a time complexity of O(... Prediction: ai\n",
      "Text: Quantum computing utilizes qubits which can exist ... Prediction: ai\n",
      "Text: The economic growth rate is influenced by multiple... Prediction: ai\n"
     ]
    }
   ],
<<<<<<< HEAD
   "source": [
    "# Function to predict\n",
    "def predict_text(text):\n",
    "    vec = tfidf.transform([text])\n",
    "    extra_feat = extra.transform([text])\n",
    "    combined = hstack([vec, extra_feat])\n",
    "    pred = model.predict(combined)[0]\n",
    "    return pred\n",
    "\n",
    "# Test human sentences\n",
    "print(\"=== Human Sentences ===\")\n",
    "for s in human_sentences:\n",
    "    print(f\"Text: {s[:50]}... Prediction: {predict_text(s)}\")\n",
    "\n",
    "# Test AI sentences\n",
    "print(\"\\n=== AI Sentences ===\")\n",
    "for s in ai_sentences:\n",
    "    print(f\"Text: {s[:50]}... Prediction: {predict_text(s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc7669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88601f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27effece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab58fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
   
   
   
>>>>>>> 66876d0c34a6a36a64ce61f28ce1f589a13629c2
