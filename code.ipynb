{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80b48d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b143f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f65d1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_set = set(\"ðŸ˜€ðŸ˜ðŸ˜‚ðŸ¤£ðŸ˜ƒðŸ˜„ðŸ˜…ðŸ˜†ðŸ˜‰ðŸ˜ŠðŸ˜‹ðŸ˜ŽðŸ˜ðŸ˜˜ðŸ˜—ðŸ˜™ðŸ˜šðŸ™‚ðŸ¤—ðŸ¤©ðŸ¤”ðŸ¤¨ðŸ˜ðŸ˜‘ðŸ˜¶ðŸ™„ðŸ˜ðŸ˜£ðŸ˜¥ðŸ˜®ðŸ¤ðŸ˜¯ðŸ˜ªðŸ˜«ðŸ˜´ðŸ˜ŒðŸ¤“ðŸ˜›ðŸ˜œðŸ˜ðŸ¤¤ðŸ˜’ðŸ˜“ðŸ˜”ðŸ˜•ðŸ™ƒðŸ¤‘ðŸ˜²â˜¹ï¸ðŸ™ðŸ˜–ðŸ˜žðŸ˜ŸðŸ˜¤ðŸ˜¢ðŸ˜­ðŸ˜¦ðŸ˜§ðŸ˜¨ðŸ˜©ðŸ¤¯ðŸ˜¬ðŸ˜°ðŸ˜±ðŸ˜³ðŸ¤ªðŸ˜µðŸ˜¡ðŸ˜ ðŸ¤¬\")\n",
    "\n",
    "class ExtraFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts):\n",
    "        emoji_count = np.array([sum(1 for ch in t if ch in emoji_set) for t in texts]).reshape(-1, 1)\n",
    "        punctuation_ratio = np.array([\n",
    "            sum(1 for c in t if c in string.punctuation) / (len(t) + 1)\n",
    "            for t in texts\n",
    "        ]).reshape(-1, 1)\n",
    "        digit_ratio = np.array([\n",
    "            sum(1 for c in t if c.isdigit()) / (len(t) + 1)\n",
    "            for t in texts\n",
    "        ]).reshape(-1, 1)\n",
    "        avg_word_len = np.array([\n",
    "            np.mean([len(w) for w in t.split()]) if len(t.split()) > 0 else 0\n",
    "            for t in texts\n",
    "        ]).reshape(-1, 1)\n",
    "\n",
    "        return np.hstack([emoji_count, punctuation_ratio, digit_ratio, avg_word_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71d711a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_data.csv\")\n",
    "\n",
    "human_df = pd.DataFrame({\"text\": df[\"Human_Content\"], \"label\": \"human\"})\n",
    "ai_df = pd.DataFrame({\"text\": df[\"AI_Content\"], \"label\": \"ai\"})  # Dummy AI row (replace later)\n",
    "\n",
    "df_final = pd.concat([human_df, ai_df], ignore_index=True)\n",
    "df_final = df_final.dropna()\n",
    "\n",
    "df_final[\"clean_text\"] = df_final[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4597ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = df_final[df_final.label == \"human\"]\n",
    "ai = df_final[df_final.label == \"ai\"]\n",
    "\n",
    "if len(human) > len(ai):\n",
    "    ai = resample(ai, replace=True, n_samples=len(human), random_state=42)\n",
    "else:\n",
    "    human = resample(human, replace=True, n_samples=len(ai), random_state=42)\n",
    "\n",
    "df_balanced = pd.concat([human, ai]).sample(frac=1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dcdc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced[\"clean_text\"], df_balanced[\"label\"],\n",
    "    test_size=0.10, random_state=42, stratify=df_balanced[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "004b8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=15000, ngram_range=(1, 3), sublinear_tf=True)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "extra = ExtraFeatures()\n",
    "X_train_extra = extra.fit_transform(X_train)\n",
    "X_test_extra = extra.transform(X_test)\n",
    "\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_extra])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_extra])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a89da17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(X_train_combined, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "231f3ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9838709677419355\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          ai       0.97      1.00      0.98        31\n",
      "       human       1.00      0.97      0.98        31\n",
      "\n",
      "    accuracy                           0.98        62\n",
      "   macro avg       0.98      0.98      0.98        62\n",
      "weighted avg       0.98      0.98      0.98        62\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[31  0]\n",
      " [ 1 30]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_combined)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a17e1cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & vectorizers saved successfully!\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, \"ai_human_model.pkl\")\n",
    "joblib.dump(tfidf, \"vectorizer.pkl\")\n",
    "joblib.dump(extra, \"extra_features.pkl\")\n",
    "\n",
    "print(\"Model & vectorizers saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2059dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "    vec = tfidf.transform([text])\n",
    "    ext = extra.transform([text])\n",
    "    combined = hstack([vec, ext])\n",
    "    return model.predict(combined)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "389c5a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: This research demonstrates a novel AI framework for text generation.\n",
      "Prediction: ai\n",
      "\n",
      "Text: Bro I just woke up and I'm still sleepy ðŸ˜‚\n",
      "Prediction: human\n",
      "\n",
      "Text: The system architecture uses transformer layers for encoding.\n",
      "Prediction: ai\n",
      "\n",
      "Text: I went to the market and bought snacks.\n",
      "Prediction: ai\n",
      "\n",
      "Text: AI improves efficiency in multiple domains.\n",
      "Prediction: ai\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    \"This research demonstrates a novel AI framework for text generation.\",\n",
    "    \"Bro I just woke up and I'm still sleepy ðŸ˜‚\",\n",
    "    \"The system architecture uses transformer layers for encoding.\",\n",
    "    \"I went to the market and bought snacks.\",\n",
    "    \"AI improves efficiency in multiple domains.\"\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(\"\\nText:\", t)\n",
    "    print(\"Prediction:\", predict_text(t))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
